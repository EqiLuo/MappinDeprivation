{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results from the PCA alalysis is then rasterized into Geotiff files, which would be later displayed in ArcGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage import exposure\n",
    "import os\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv file of multiple deprivation degrees\n",
    "df = pd.read_csv(r\"C:\\Users\\EQiLu\\MSc Thesis\\PCA results\\0318\\builtup_all_variables_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rows  columns   FAC1_1   FAC2_1   FAC3_1   FAC4_1   FAC5_1   FAC6_1  \\\n",
      "0         1      284  0.34835  1.07187 -1.67636 -0.66810 -0.48305  0.03390   \n",
      "1         3      271 -0.04883  0.75246 -1.32319 -0.43809 -0.60566 -0.03077   \n",
      "2         3      272  0.05303  0.72162 -1.49915 -0.43077 -0.56450  0.05425   \n",
      "3         3      297  0.16747  1.16711 -1.23108 -0.87211 -0.51496 -0.00111   \n",
      "4         3      298  0.15836  1.14421 -1.28117 -0.69291 -0.55032 -0.00457   \n",
      "...     ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "45721   251      125 -0.01558  0.12814 -0.62016 -0.83387  0.40006  0.23757   \n",
      "45722   251      130 -0.28080 -0.12374 -0.72869  0.62742  0.34067 -0.29328   \n",
      "45723   252      125 -0.02582  0.10826 -0.60194 -0.50748  0.38875  0.04901   \n",
      "45724   252      129 -0.20575  0.05413 -0.40975 -0.64698  0.37265  0.06379   \n",
      "45725   252      130 -0.32578 -0.00275 -0.48670  0.08561  0.31955 -0.14016   \n",
      "\n",
      "       sumed score  \n",
      "0         -0.86111  \n",
      "1         -0.45496  \n",
      "2         -0.21652  \n",
      "3         -1.49168  \n",
      "4         -1.26920  \n",
      "...            ...  \n",
      "45721      0.31136  \n",
      "45722      1.80804  \n",
      "45723      0.44978  \n",
      "45724      0.35083  \n",
      "45725      1.08023  \n",
      "\n",
      "[45726 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1    2    3    4    5    6    7    8    9    10   ...  425  426  427  \\\n",
      "1    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "2    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "3    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "4    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "5    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "249  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "250  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "\n",
      "     428  429  430  431  432  433  434  \n",
      "1    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "2    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "3    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "5    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  \n",
      "249  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "250  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[253 rows x 434 columns]\n",
      "(253, 434)\n"
     ]
    }
   ],
   "source": [
    "# create the base layer, a 2-d dataframe of the same width*height at 100m grid as the original geotiff\n",
    "\n",
    "base = pd.DataFrame(index = range(1,254) , columns= range(1,435))\n",
    "print(base)\n",
    "print(base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass along the deprivation indices accoording to the (row,column) coordinates.  \n",
    "\n",
    "for row in df.itertuples(index = False):\n",
    "    base.at[row[0]+1,row[1]+1] = row[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1    2    3    4    5    6    7    8    9    10   ...  425  426  427  \\\n",
      "1    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "2    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "3    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "4    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "5    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "249  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "250  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
      "\n",
      "     428  429  430  431  432  433  434  \n",
      "1    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "2    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "3    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "4    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "5    NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  \n",
      "249  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "250  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[253 rows x 434 columns]\n",
      "(253, 434)\n"
     ]
    }
   ],
   "source": [
    "print(base)\n",
    "print(base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# convert the pandas dataframe to numpy array\n",
    "\n",
    "final = base.to_numpy()\n",
    "print(final)\n",
    "print(final.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chenge the datatype into numerical\n",
    "\n",
    "final = final.astype(float)\n",
    "final.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import osr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2raster(newRasterfn, dataset, array, dtype):\n",
    "    \"\"\"\n",
    "    save GTiff file from numpy.array\n",
    "    input:\n",
    "        newRasterfn: save file name\n",
    "        dataset : original tif file\n",
    "        array : numpy.array\n",
    "        dtype: Byte or Float32.\n",
    "    \"\"\"\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX, pixelWidth, b, originY, d, pixelHeight = dataset.GetGeoTransform() \n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "\n",
    "    # set data type to save.\n",
    "    GDT_dtype = gdal.GDT_Unknown\n",
    "    if dtype == \"Byte\": \n",
    "        GDT_dtype = gdal.GDT_Byte\n",
    "    elif dtype == \"Float32\":\n",
    "        GDT_dtype = gdal.GDT_Float32\n",
    "    else:\n",
    "        print(\"Not supported data type.\")\n",
    "\n",
    "    # set number of band.\n",
    "    if array.ndim == 2:\n",
    "        band_num = 1\n",
    "    else:\n",
    "        band_num = array.shape[2]\n",
    "\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, band_num, GDT_dtype)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "\n",
    "    # Loop over all bands.\n",
    "    for b in range(band_num):\n",
    "        outband = outRaster.GetRasterBand(b + 1)\n",
    "        # Read in the band's data into the third dimension of our array\n",
    "        if band_num == 1:\n",
    "            outband.WriteArray(array)\n",
    "        else:\n",
    "            outband.WriteArray(array[:,:,b])\n",
    "\n",
    "    # setteing srs from input tif file.\n",
    "    prj=dataset.GetProjection()\n",
    "    outRasterSRS = osr.SpatialReference(wkt=prj)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = gdal.Open(r'C:\\Users\\EQiLu\\MSc Thesis\\100m Input March\\nai_OSM_dis_major_roads_2020.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2raster(r'C:\\Users\\EQiLu\\MSc Thesis\\Result Map\\0318\\builtup_all_variables_score.tif', ori_data, final,\"Float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
